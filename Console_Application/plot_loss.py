import matplotlib
from matplotlib import pyplot as plt
import numpy as np

def plot_stats():
	epochs = np.array([range(100)])
	res_training_loss = np.array([
		0.5789, 0.5491, 0.5230, 0.5089, 0.5026,
		0.4974, 0.4936, 0.4878, 0.4885, 0.4859,
		0.4830, 0.4783, 0.4777, 0.4745, 0.4725,
		0.4687, 0.4676, 0.4679, 0.4665, 0.4637,
		0.4639, 0.4618, 0.4623, 0.4562, 0.4578,
		0.4562, 0.4572, 0.4524, 0.4526, 0.4511,
		0.4509, 0.4491, 0.4461, 0.4452, 0.4451,
		0.4414, 0.4407, 0.4368, 0.4337, 0.4343,
		0.4333, 0.4035, 0.4268, 0.4241, 0.4205,
		0.4196, 0.4167, 0.4105, 0.4077, 0.4056,
		0.4044, 0.3993, 0.3966, 0.3952, 0.3906,
		0.3844, 0.3822, 0.3793, 0.3713, 0.3720,
		0.3651, 0.3649, 0.3608, 0.3566, 0.3540,
		0.3507, 0.3501, 0.3399, 0.3371, 0.3352,
		0.3307, 0.3329, 0.3255, 0.3224, 0.3205,
		0.3116, 0.3150, 0.3141, 0.3098, 0.3064,
		0.3033, 0.3037, 0.3006, 0.2976, 0.2943,
		0.2965, 0.2976, 0.2931, 0.2920, 0.2938,
		0.2974, 0.2898, 0.2856, 0.2861, 0.2863,
		0.2887, 0.2868, 0.2858, 0.2862, 0.2869
		])
	res_val_loss = np.array([
		0.7635, 6.5698, 6.3170, 4.7991, 6.5934,
		6.7055, 5.0767, 5.3470, 5.7660, 1.0772,
		1.2975, 2.3606, 0.7595, 3.7361, 5.4690,
		0.7627, 0.8193, 0.7305, 1.0738, 0.8105,
		0.7905, 0.8397, 1.4291, 1.2157, 0.7772,
		0.7911, 0.7605, 0.7678, 0.7594, 0.7625,
		0.7611, 0.7629, 0.7625, 0.7593, 0.7588,
		0.7597, 0.7576, 0.7595, 0.7592, 0.7594,
		0.7589, 0.7594, 0.7594, 0.7594, 0.7594,
		0.7594, 0.7594, 0.7594, 0.7594, 0.7594,
		0.7623, 0.7594, 0.7594, 0.7594, 0.7594,
		0.7594, 0.7603, 0.7603, 0.7594, 0.7594,
		0.7619, 0.7607, 0.7595, 0.7622, 0.7612,
		0.7594, 0.7619, 0.7613, 0.7611, 0.7607,
		0.7608, 0.7619, 0.7617, 0.7615, 0.7606,
		0.7605, 0.7613, 0.7604, 0.7589, 0.7579,
		0.7587, 0.7594, 0.7585, 0.7575, 0.7587,
		0.7580, 0.7551, 0.7580, 0.7563, 0.7525,
		0.7525, 0.7550, 0.7517, 0.7500, 0.7488,
		0.7488, 0.7467, 0.7455, 0.7438, 0.7422
		])

	mask_training_loss = np.array([
		2.4847, 1.6430, 1.5727, 1.5188, 1.4498,
		1.4988, 1.4571, 1.4729, 1.4059, 1.4305,
		1.4615, 1.4667, 1.3284, 1.2047, 1.2593,
		1.1798, 1.1529, 1.3443, 1.2857, 1.3959,
		1.3151, 1.3784, 1.2810, 1.3028, 1.3389,
		1.3224, 1.3373, 1.2093, 1.3261, 1.3444,
		1.2108, 1.2971, 1.1038, 1.4009, 1.2011,
		1.1684, 1.2184, 1.2918, 1.2379, 1.1752,
		1.3044, 1.1971, 1.2220, 1.2049, 1.1009,
		1.3612, 1.2359, 1.2153, 1.2974, 1.2458,
		1.2154, 1.1181, 1.1991, 1.1702, 1.2788,
		1.2155, 1.2021, 1.2309, 1.1798, 1.1099,
		0.9938, 1.1317, 1.1522, 1.1160, 1.0794,
		1.1485, 1.1646, 1.0218, 1.0422, 1.0390,
		0.8969, 1.0222, 1.2001, 1.0954, 1.0654,
		1.1040, 1.1182, 1.1229, 1.0543, 0.9967,
		1.1519, 1.0220, 1.0930, 1.0283, 1.0436,
		1.0965, 1.0204, 1.1440, 1.0408, 1.1630,
		1.0309, 1.1158, 1.2013, 1.0660, 1.0845,
		1.0821, 0.9252, 0.9873, 1.0334, 1.0364
		])
	mask_val_loss = np.array([
		2.3406, 2.9058, 2.1777, 2.1057, 2.6728,
		2.0016, 2.7837, 2.1731, 2.2131, 1.9571,
		2.4199, 2.2037, 2.5004, 2.2853, 2.3013,
		2.3376, 2.3924, 2.2919, 2.1069, 2.0891,
		2.0916, 1.8648, 2.0950, 2.5544, 2.4295,
		2.5710, 1.8505, 2.1106, 2.0636, 2.2479,
		2.0572, 1.8681, 3.0160, 2.3906, 2.1100,
		1.8972, 2.0390, 2.5978, 2.0402, 2.3822,
		2.2112, 2.4608, 1.9844, 1.8878, 2.3411,
		2.2199, 2.4072, 2.1570, 1.9094, 1.9916,
		1.8484, 2.0913, 1.9180, 2.0478, 1.8762,
		1.7610, 2.1319, 2.0942, 1.8092, 1.9525,
		2.0057, 1.8330, 2.1959, 2.2373, 1.9019,
		1.9540, 1.8445, 2.0407, 2.0550, 2.1595,
		2.3273, 1.8101, 1.9100, 1.7735, 2.2149,
		2.0429, 2.1043, 1.8569, 1.9535, 2.4119,
		1.9760, 2.4166, 2.1041, 2.1606, 2.3254,
		2.0259, 2.4826, 2.2708, 2.1778, 1.9998,
		2.0259, 2.1473, 1.9383, 1.9834, 1.9068,
		2.1545, 2.3686, 1.8964, 1.7874, 1.7421
		])

	chex_training_loss = np.array([
		0.1008, 0.0842, 0.0797, 0.0782, 0.0764,
		0.0746, 0.0734, 0.0724, 0.0708, 0.0696,
		0.0688, 0.0676, 0.0667, 0.0658, 0.0648,
		0.0639, 0.0633, 0.0623, 0.0621, 0.0614,
		0.0609, 0.0603, 0.0600, 0.0597, 0.0590,
		0.0591, 0.0585, 0.0581, 0.0575, 0.0572,
		0.0567, 0.0560, 0.0555, 0.0548, 0.0544,
		0.0538, 0.0529, 0.0523, 0.0515, 0.0505,
		0.0495, 0.0484, 0.0473, 0.0463, 0.0448,
		0.0436, 0.0421, 0.0407, 0.0392, 0.0382,
		0.0365, 0.0350, 0.0343, 0.0328, 0.0316,
		0.0308, 0.0294, 0.0288, 0.0278, 0.0270,
		0.0259, 0.0254, 0.0249, 0.0243, 0.0239,
		0.0232, 0.0228, 0.0221, 0.0220, 0.0216,
		0.0212, 0.0208, 0.0205, 0.0200, 0.0201,
		0.0193, 0.0194, 0.0192, 0.0187, 0.0189,
		0.0186, 0.0181, 0.0180, 0.0180, 0.0180,
		0.0175, 0.0173, 0.0171, 0.0170, 0.0171,
		0.0170, 0.0166, 0.0170, 0.0167, 0.0164,
		0.0161, 0.0165, 0.0162, 0.0162, 0.0155
		])
	chex_val_loss = np.array([
		0.1352, 0.2762, 0.1053, 0.2985, 0.1009,
		0.0804, 0.0972, 0.1538, 0.0831, 0.0975,
		0.0954, 0.0617, 0.0815, 0.0848, 0.1014,
		0.0772, 0.0745, 0.0762, 0.0617, 0.0564,
		0.0607, 0.0646, 0.0571, 0.0677, 0.0584,
		0.0655, 0.0572, 0.0615, 0.0571, 0.0634,
		0.0611, 0.0979, 0.0590, 0.0553, 0.0562,
		0.0622, 0.0590, 0.0604, 0.0677, 0.0631,
		0.0619, 0.0580, 0.0664, 0.0609, 0.0667,
		0.0681, 0.0718, 0.0727, 0.0874, 0.0727,
		0.0706, 0.0708, 0.1059, 0.0792, 0.0766,
		0.0787, 0.0812, 0.0774, 0.0914, 0.0821,
		0.0837, 0.0951, 0.0907, 0.0852, 0.1035,
		0.0957, 0.0968, 0.0945, 0.0894, 0.1058,
		0.0962, 0.0973, 0.0940, 0.1249, 0.1174,
		0.1010, 0.1152, 0.0985, 0.1052, 0.1009,
		0.0999, 0.1034, 0.1118, 0.1090, 0.1038,
		0.1225, 0.1103, 0.1097, 0.1059, 0.0990,
		0.1080, 0.1223, 0.1271, 0.1211, 0.1040,
		0.1198, 0.1024, 0.1130, 0.1034, 0.1183
		])

	epochs = np.reshape(epochs, (100,))
	plt.figure()


	plt.subplot(3, 2, 1)
	plt.plot(epochs, res_training_loss, label="ResNet Training Loss", linewidth=2.0)
	plt.xlabel('Epochs')
	plt.ylabel('Loss')
	plt.title('ResNet Training Loss')
	plt.subplot(3, 2, 2)
	plt.plot(epochs, res_val_loss, label="ResNet Validation Loss", linewidth=2.0)
	plt.xlabel('Epochs')
	plt.ylabel('Val_Loss')
	plt.title('ResNet Validation Loss')
	plt.subplot(3, 2, 3)
	plt.plot(epochs, mask_training_loss, label="Mask-RCNN Training Loss", linewidth=2.0)
	plt.xlabel('Epochs')
	plt.ylabel('Loss')
	plt.title('Mask-RCNN Training Loss')
	plt.subplot(3, 2, 4)
	plt.plot(epochs, mask_val_loss, label="Mask-RCNN Validation Loss", linewidth=2.0)
	plt.xlabel('Epochs')
	plt.ylabel('Val_Loss')
	plt.title('Mask-RCNN Validation Loss')
	plt.subplot(3, 2, 5)
	plt.plot(epochs, chex_training_loss, label="ChexNet Training Loss", linewidth=2.0)
	plt.xlabel('Epochs')
	plt.ylabel('Loss')
	plt.title('ChexNet Training Loss')
	plt.subplot(3, 2, 6)
	plt.plot(epochs, chex_val_loss, label="ChexNet Validation Loss", linewidth=2.0)
	plt.xlabel('Epochs')
	plt.ylabel('Val_Loss')
	plt.title('ChexNet Validation Loss')
	plt.tight_layout()
	plt.show()
