import matplotlib
from matplotlib import pyplot as plt
import numpy as np

def plot_stats():
  epochs = np.array([range(100)])
  epochs_resnet = np.array([range(50)])
  res_training_loss = np.array([
		0.5060, 0.4633, 0.4452, 0.4296, 0.4210,
		0.4140, 0.4092, 0.4054, 0.4033, 0.3980,
		0.3965, 0.3943, 0.3921, 0.3915, 0.3908,
		0.3892, 0.3884, 0.3862, 0.3839, 0.3832,
		0.3809, 0.3799, 0.3790, 0.3792, 0.3778,
		0.3792, 0.3756, 0.3736, 0.3704, 0.3695,
		0.3694, 0.3679, 0.3661, 0.3650, 0.3643,
		0.3646, 0.3635, 0.3625, 0.3608, 0.3603,
		0.3588, 0.3576, 0.3572, 0.3577, 0.3558,
		0.3559, 0.3560, 0.3548, 0.3553, 0.3535
		])

  res_val_loss = np.array([
		0.6624, 0.5567, 0.4743, 0.4376, 0.4358,
		0.4197, 0.4258, 0.4098, 0.4202, 0.4399,
		0.4019, 0.4315, 0.3980, 0.4032, 0.4169,
		0.3990, 0.3897, 0.3889, 0.3888, 0.3871,
		0.4103, 0.3863, 0.3844, 0.3863, 0.3889,
		0.3896, 0.3881, 0.3865, 0.3833, 0.3843,
		0.3928, 0.3833, 0.3828, 0.3853, 0.3840,
		0.3855, 0.3853, 0.3856, 0.3851, 0.3842,
		0.3838, 0.3857, 0.3877, 0.3847, 0.3845,
		0.3852, 0.3849, 0.3851, 0.3847, 0.3846
		])

  res_acc = np.array([
		0.8083, 0.8983, 0.9435, 0.9672, 0.9589, 
		0.9702, 0.9712, 0.9747, 0.9716, 0.9706, 
		0.9674, 0.9716, 0.9742, 0.9659, 0.9744, 
		0.9721, 0.9736, 0.9728, 0.9750, 0.9696, 
		0.9746, 0.9711, 0.9717, 0.9706, 0.9715, 
		0.9741, 0.9680, 0.9693, 0.9715, 0.9709, 
		0.9737, 0.9710, 0.9723, 0.9717, 0.9716, 
		0.9734, 0.9708, 0.9740, 0.9717, 0.9709, 
		0.9723, 0.9716, 0.9703, 0.9717, 0.9723, 
		0.9712, 0.9715, 0.9712, 0.9715, 0.9715
		])

  mask_training_loss = np.array([
		2.4847, 1.6430, 1.5727, 1.5188, 1.4498,
		1.4988, 1.4571, 1.4729, 1.4059, 1.4305,
		1.4615, 1.4667, 1.3284, 1.2047, 1.2593,
		1.1798, 1.1529, 1.3443, 1.2857, 1.3959,
		1.3151, 1.3784, 1.2810, 1.3028, 1.3389,
		1.3224, 1.3373, 1.2093, 1.3261, 1.3444,
		1.2108, 1.2971, 1.1038, 1.4009, 1.2011,
		1.1684, 1.2184, 1.2918, 1.2379, 1.1752,
		1.3044, 1.1971, 1.2220, 1.2049, 1.1009,
		1.3612, 1.2359, 1.2153, 1.2974, 1.2458,
		1.2154, 1.1181, 1.1991, 1.1702, 1.2788,
		1.2155, 1.2021, 1.2309, 1.1798, 1.1099,
		0.9938, 1.1317, 1.1522, 1.1160, 1.0794,
		1.1485, 1.1646, 1.0218, 1.0422, 1.0390,
		0.8969, 1.0222, 1.2001, 1.0954, 1.0654,
		1.1040, 1.1182, 1.1229, 1.0543, 0.9967,
		1.1519, 1.0220, 1.0930, 1.0283, 1.0436,
		1.0965, 1.0204, 1.1440, 1.0408, 1.1630,
		1.0309, 1.1158, 1.2013, 1.0660, 1.0845,
		1.0821, 0.9252, 0.9873, 1.0334, 1.0364
		])

  mask_val_loss = np.array([
		2.3406, 2.9058, 2.1777, 2.1057, 2.6728,
		2.0016, 2.7837, 2.1731, 2.2131, 1.9571,
		2.4199, 2.2037, 2.5004, 2.2853, 2.3013,
		2.3376, 2.3924, 2.2919, 2.1069, 2.0891,
		2.0916, 1.8648, 2.0950, 2.5544, 2.4295,
		2.5710, 1.8505, 2.1106, 2.0636, 2.2479,
		2.0572, 1.8681, 3.0160, 2.3906, 2.1100,
		1.8972, 2.0390, 2.5978, 2.0402, 2.3822,
		2.2112, 2.4608, 1.9844, 1.8878, 2.3411,
		2.2199, 2.4072, 2.1570, 1.9094, 1.9916,
		1.8484, 2.0913, 1.9180, 2.0478, 1.8762,
		1.7610, 2.1319, 2.0942, 1.8092, 1.9525,
		2.0057, 1.8330, 2.1959, 2.2373, 1.9019,
		1.9540, 1.8445, 2.0407, 2.0550, 2.1595,
		2.3273, 1.8101, 1.9100, 1.7735, 2.2149,
		2.0429, 2.1043, 1.8569, 1.9535, 2.4119,
		1.9760, 2.4166, 2.1041, 2.1606, 2.3254,
		2.0259, 2.4826, 2.2708, 2.1778, 1.9998,
		2.0259, 2.1473, 1.9383, 1.9834, 1.9068,
		2.1545, 2.3686, 1.8964, 1.7874, 1.7421
		])

  chex_training_loss = np.array([
		0.1008, 0.0842, 0.0797, 0.0782, 0.0764,
		0.0746, 0.0734, 0.0724, 0.0708, 0.0696,
		0.0688, 0.0676, 0.0667, 0.0658, 0.0648,
		0.0639, 0.0633, 0.0623, 0.0621, 0.0614,
		0.0609, 0.0603, 0.0600, 0.0597, 0.0590,
		0.0591, 0.0585, 0.0581, 0.0575, 0.0572,
		0.0567, 0.0560, 0.0555, 0.0548, 0.0544,
		0.0538, 0.0529, 0.0523, 0.0515, 0.0505,
		0.0495, 0.0484, 0.0473, 0.0463, 0.0448,
		0.0436, 0.0421, 0.0407, 0.0392, 0.0382,
		0.0365, 0.0350, 0.0343, 0.0328, 0.0316,
		0.0308, 0.0294, 0.0288, 0.0278, 0.0270,
		0.0259, 0.0254, 0.0249, 0.0243, 0.0239,
		0.0232, 0.0228, 0.0221, 0.0220, 0.0216,
		0.0212, 0.0208, 0.0205, 0.0200, 0.0201,
		0.0193, 0.0194, 0.0192, 0.0187, 0.0189,
		0.0186, 0.0181, 0.0180, 0.0180, 0.0180,
		0.0175, 0.0173, 0.0171, 0.0170, 0.0171,
		0.0170, 0.0166, 0.0170, 0.0167, 0.0164,
		0.0161, 0.0165, 0.0162, 0.0162, 0.0155
		])

  chex_val_loss = np.array([
		0.1352, 0.2762, 0.1053, 0.2985, 0.1009,
		0.0804, 0.0972, 0.1538, 0.0831, 0.0975,
		0.0954, 0.0617, 0.0815, 0.0848, 0.1014,
		0.0772, 0.0745, 0.0762, 0.0617, 0.0564,
		0.0607, 0.0646, 0.0571, 0.0677, 0.0584,
		0.0655, 0.0572, 0.0615, 0.0571, 0.0634,
		0.0611, 0.0979, 0.0590, 0.0553, 0.0562,
		0.0622, 0.0590, 0.0604, 0.0677, 0.0631,
		0.0619, 0.0580, 0.0664, 0.0609, 0.0667,
		0.0681, 0.0718, 0.0727, 0.0874, 0.0727,
		0.0706, 0.0708, 0.1059, 0.0792, 0.0766,
		0.0787, 0.0812, 0.0774, 0.0914, 0.0821,
		0.0837, 0.0951, 0.0907, 0.0852, 0.1035,
		0.0957, 0.0968, 0.0945, 0.0894, 0.1058,
		0.0962, 0.0973, 0.0940, 0.1249, 0.1174,
		0.1010, 0.1152, 0.0985, 0.1052, 0.1009,
		0.0999, 0.1034, 0.1118, 0.1090, 0.1038,
		0.1225, 0.1103, 0.1097, 0.1059, 0.0990,
		0.1080, 0.1223, 0.1271, 0.1211, 0.1040,
		0.1198, 0.1024, 0.1130, 0.1034, 0.1183
		])

  chex_acc = np.array([
		0.9726, 0.9732, 0.9734, 0.9736, 0.9738,
		0.9742, 0.9745, 0.9745, 0.9750, 0.9751,
		0.9754, 0.9756, 0.9757, 0.9758, 0.9761,
		0.9762, 0.9764, 0.9766, 0.9766, 0.9766,
		0.9767, 0.9769, 0.9770, 0.9770, 0.9772,
		0.9771, 0.9773, 0.9775, 0.9776, 0.9777, 
		0.9778, 0.9780, 0.9781, 0.9783, 0.9784,
		0.9785, 0.9788, 0.9790, 0.9795, 0.9797, 
		0.9800, 0.9804, 0.9809, 0.9812, 0.9819,
		0.9824, 0.9831, 0.9835, 0.9841, 0.9846, 
		0.9853, 0.9859, 0.9861, 0.9867, 0.9873, 
		0.9876, 0.9881, 0.9884, 0.9888, 0.9890, 
		0.9895, 0.9897, 0.9899, 0.9901, 0.9902, 
		0.9905, 0.9906, 0.9909, 0.9909, 0.9911,
		0.9912, 0.9913, 0.9914, 0.9917, 0.9916,
		0.9919, 0.9919, 0.9919, 0.9921, 0.9920, 
		0.9921, 0.9923, 0.9923, 0.9923, 0.9923,
		0.9925, 0.9925, 0.9926, 0.9926, 0.9926,
		0.9926, 0.9927, 0.9926, 0.9927, 0.9928,
		0.9929, 0.9927, 0.9929, 0.9929, 0.9931
		])

  epochs = np.reshape(epochs, (100,))
  epochs_resnet = np.reshape(epochs_resnet, (50,))
  plt.figure()


  plt.subplot(3, 3, 1)
  plt.plot(epochs_resnet, res_training_loss, label="ResNet Training Loss", linewidth=2.0)
  plt.xlabel('Epochs')
  plt.ylabel('Loss')
  plt.title('ResNet Training Loss')
  plt.subplot(3, 3, 2)
  plt.plot(epochs_resnet, res_val_loss, label="ResNet Validation Loss", linewidth=2.0)
  plt.xlabel('Epochs')
  plt.ylabel('Val_Loss')
  plt.title('ResNet Validation Loss')
  plt.subplot(3, 3, 3)
  plt.plot(epochs_resnet, res_acc, label="ResNet Accuracy", linewidth=2.0)
  plt.xlabel('Epochs')
  plt.ylabel('Accuracy')
  plt.title('ResNet Accuracy')
  plt.subplot(3, 3, 4)
  plt.plot(epochs, mask_training_loss, label="Mask-RCNN Training Loss", linewidth=2.0)
  plt.xlabel('Epochs')
  plt.ylabel('Loss')
  plt.title('Mask-RCNN Training Loss')
  plt.subplot(3, 3, 5)
  plt.plot(epochs, mask_val_loss, label="Mask-RCNN Validation Loss", linewidth=2.0)
  plt.xlabel('Epochs')
  plt.ylabel('Val_Loss')
  plt.title('Mask-RCNN Validation Loss')
  plt.subplot(3, 3, 7)
  plt.plot(epochs, chex_training_loss, label="ChexNet Training Loss", linewidth=2.0)
  plt.xlabel('Epochs')
  plt.ylabel('Loss')
  plt.title('ChexNet Training Loss')
  plt.subplot(3, 3, 8)
  plt.plot(epochs, chex_val_loss, label="ChexNet Validation Loss", linewidth=2.0)
  plt.xlabel('Epochs')
  plt.ylabel('Val_Loss')
  plt.title('ChexNet Validation Loss')
  plt.subplot(3, 3, 9)
  plt.plot(epochs, chex_acc, label="ChexNet Accuracy", linewidth=2.0)
  plt.xlabel('Epochs')
  plt.ylabel('Accuracy')
  plt.title('ChexNet Accuracy')
  plt.tight_layout()
  plt.show()
plot_stats()