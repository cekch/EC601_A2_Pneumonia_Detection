{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "323f22eb85744ef15a54946a58a017e52942133e"
   },
   "source": [
    "# Overview\n",
    "The goal is to make a simple Keras model for predicting which category an image falls in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "b148e50a8ba9440c2b4ee582496dbf63608cb92c"
   },
   "outputs": [],
   "source": [
    "# params we will probably want to do some hyperparameter optimization later\n",
    "BASE_MODEL= 'RESNET52' # ['VGG16', 'RESNET52', 'InceptionV3', 'Xception', 'DenseNet169', 'DenseNet121']\n",
    "IMG_SIZE = (224, 224) # [(224, 224), (384, 384), (512, 512), (640, 640)]\n",
    "BATCH_SIZE = 24 # [1, 8, 16, 24]\n",
    "DENSE_COUNT = 128 # [32, 64, 128, 256]\n",
    "DROPOUT = 0.25 # [0, 0.25, 0.5]\n",
    "LEARN_RATE = 1e-4 # [1e-4, 1e-3, 4e-3]\n",
    "TRAIN_SAMPLES =  15000 #8000 # [3000, 6000, 15000]\n",
    "TEST_SAMPLES = 5000 #800\n",
    "USE_ATTN = False # [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28989 images\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>Target</th>\n",
       "      <th>class</th>\n",
       "      <th>boxes</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5051</th>\n",
       "      <td>43cc99ab-f27c-4fa1-8f6c-3f28a2eb102e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>No Lung Opacity / Not Normal</td>\n",
       "      <td>1</td>\n",
       "      <td>./input/rsna-pneumonia-detection-challenge/sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24201</th>\n",
       "      <td>d9815385-9c37-4484-8785-92b3eed84586</td>\n",
       "      <td>236.0</td>\n",
       "      <td>579.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lung Opacity</td>\n",
       "      <td>1</td>\n",
       "      <td>./input/rsna-pneumonia-detection-challenge/sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28614</th>\n",
       "      <td>fd1550bf-b079-4ff1-a1f3-8aa821c4b83b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1</td>\n",
       "      <td>./input/rsna-pneumonia-detection-challenge/sta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  patientId      x      y  width  height  \\\n",
       "5051   43cc99ab-f27c-4fa1-8f6c-3f28a2eb102e    NaN    NaN    NaN     NaN   \n",
       "24201  d9815385-9c37-4484-8785-92b3eed84586  236.0  579.0  163.0   123.0   \n",
       "28614  fd1550bf-b079-4ff1-a1f3-8aa821c4b83b    NaN    NaN    NaN     NaN   \n",
       "\n",
       "       Target                         class  boxes  \\\n",
       "5051        0  No Lung Opacity / Not Normal      1   \n",
       "24201       1                  Lung Opacity      1   \n",
       "28614       0                        Normal      1   \n",
       "\n",
       "                                                    path  \n",
       "5051   ./input/rsna-pneumonia-detection-challenge/sta...  \n",
       "24201  ./input/rsna-pneumonia-detection-challenge/sta...  \n",
       "28614  ./input/rsna-pneumonia-detection-challenge/sta...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_bbox_df = pd.read_csv('./image_bbox_full.csv')\n",
    "image_bbox_df['path'] = image_bbox_df['path'].map(lambda x: \n",
    "                                                  x.replace('input', \n",
    "                                                            'input/rsna-pneumonia-detection-challenge'))\n",
    "print(image_bbox_df.shape[0], 'images')\n",
    "image_bbox_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "f4925492adb4f55f01794709cb751a42ca5c2177"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>Target</th>\n",
       "      <th>class</th>\n",
       "      <th>boxes</th>\n",
       "      <th>path</th>\n",
       "      <th>class_idx</th>\n",
       "      <th>class_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>17f64400-da64-4633-96a1-1287f35a5022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>No Lung Opacity / Not Normal</td>\n",
       "      <td>1</td>\n",
       "      <td>./input/rsna-pneumonia-detection-challenge/sta...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>06d5a58d-baf1-4937-bfc3-00db1fb2b1be</td>\n",
       "      <td>566.0</td>\n",
       "      <td>621.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lung Opacity</td>\n",
       "      <td>2</td>\n",
       "      <td>./input/rsna-pneumonia-detection-challenge/sta...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10208</th>\n",
       "      <td>6d4f8b2d-1509-43d2-8620-99623234d622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>No Lung Opacity / Not Normal</td>\n",
       "      <td>1</td>\n",
       "      <td>./input/rsna-pneumonia-detection-challenge/sta...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  patientId      x      y  width  height  \\\n",
       "1683   17f64400-da64-4633-96a1-1287f35a5022    NaN    NaN    NaN     NaN   \n",
       "323    06d5a58d-baf1-4937-bfc3-00db1fb2b1be  566.0  621.0  255.0   315.0   \n",
       "10208  6d4f8b2d-1509-43d2-8620-99623234d622    NaN    NaN    NaN     NaN   \n",
       "\n",
       "       Target                         class  boxes  \\\n",
       "1683        0  No Lung Opacity / Not Normal      1   \n",
       "323         1                  Lung Opacity      2   \n",
       "10208       0  No Lung Opacity / Not Normal      1   \n",
       "\n",
       "                                                    path  class_idx  \\\n",
       "1683   ./input/rsna-pneumonia-detection-challenge/sta...          1   \n",
       "323    ./input/rsna-pneumonia-detection-challenge/sta...          0   \n",
       "10208  ./input/rsna-pneumonia-detection-challenge/sta...          1   \n",
       "\n",
       "             class_vec  \n",
       "1683   [0.0, 1.0, 0.0]  \n",
       "323    [1.0, 0.0, 0.0]  \n",
       "10208  [0.0, 1.0, 0.0]  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the labels in the right format\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "class_enc = LabelEncoder()\n",
    "image_bbox_df['class_idx'] = class_enc.fit_transform(image_bbox_df['class'])\n",
    "oh_enc = OneHotEncoder(sparse=False)\n",
    "image_bbox_df['class_vec'] = oh_enc.fit_transform(\n",
    "    image_bbox_df['class_idx'].values.reshape(-1, 1)).tolist() \n",
    "image_bbox_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b562636a2a48a0557fb16d98841fcbf650245641"
   },
   "source": [
    "# Split into Training and Validation\n",
    "This will give us some feedback on how well our model is doing and if we are overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "c12bfd5115610163c2b63ece8fa8845bb7792327"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20547, 11) training data\n",
      "(5137, 11) validation data\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "image_df = image_bbox_df.groupby('patientId').apply(lambda x: x.sample(1))\n",
    "'''raw_train_df, valid_df = train_test_split(image_df, test_size=0.20, random_state=2018,\n",
    "                                    stratify=image_df['class'])\n",
    "print(raw_train_df.shape, 'training data')'''\n",
    "train_df, valid_df = train_test_split(image_df, test_size=0.20, random_state=2018,\n",
    "                                    stratify=image_df['class'])\n",
    "print(train_df.shape, 'training data')\n",
    "print(valid_df.shape, 'validation data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "71c22947c5007a28627b41af14ee8a7f2e990174"
   },
   "source": [
    "## Balance Training Set\n",
    "And reduce the total image count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "48b8d60f4435d3ca50d11e12d4eee518c6972ab5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Commenting this out, because I want to use the full dataset for now\\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\\nraw_train_df.groupby('class').size().plot.bar(ax=ax1)\\ntrain_df = raw_train_df.groupby('class').    apply(lambda x: x.sample(TRAIN_SAMPLES//3)).    reset_index(drop=True)\\ntrain_df.groupby('class').size().plot.bar(ax=ax2) \\nprint(train_df.shape[0], 'new training size')\\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Commenting this out, because I want to use the full dataset for now\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n",
    "raw_train_df.groupby('class').size().plot.bar(ax=ax1)\n",
    "train_df = raw_train_df.groupby('class').\\\n",
    "    apply(lambda x: x.sample(TRAIN_SAMPLES//3)).\\\n",
    "    reset_index(drop=True)\n",
    "train_df.groupby('class').size().plot.bar(ax=ax2) \n",
    "print(train_df.shape[0], 'new training size')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e9b274bfc403678cd6428b8d245bcb1a08fa0808"
   },
   "source": [
    "## Keras Image Transplantation\n",
    "Since Keras is design for color jpeg images we need to hack a bit to make it dicom friendly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_uuid": "9548edfc1a318edfcd2a387468a5b7950a376cc5"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # keras 2.2\n",
    "    import keras_preprocessing.image as KPImage\n",
    "except:\n",
    "    # keras 2.1\n",
    "    import keras.preprocessing.image as KPImage\n",
    "    \n",
    "from PIL import Image\n",
    "import pydicom\n",
    "def read_dicom_image(in_path):\n",
    "    img_arr = pydicom.read_file(in_path).pixel_array\n",
    "    return img_arr/img_arr.max()\n",
    "    \n",
    "class medical_pil():\n",
    "    @staticmethod\n",
    "    def open(in_path):\n",
    "        if '.dcm' in in_path:\n",
    "            c_slice = read_dicom_image(in_path)\n",
    "            int_slice =  (255*c_slice).clip(0, 255).astype(np.uint8) # 8bit images are more friendly\n",
    "            return Image.fromarray(int_slice)\n",
    "        else:\n",
    "            return Image.open(in_path)\n",
    "    fromarray = Image.fromarray\n",
    "KPImage.pil_image = medical_pil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a0d2ca01b3719e94212234b9d3e4ed43520262eb"
   },
   "source": [
    "# Data Augmentation\n",
    "Here we can perform simple augmentation (the `imgaug` and `Augmentation` packages offer much more flexiblity). In order to setup the augmentation we need to know which model we are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "b655a151895a67cb66b41ccf0bf97c5cd80cc0f2"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "if BASE_MODEL=='VGG16':\n",
    "    from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\n",
    "elif BASE_MODEL=='RESNET52':\n",
    "    from keras.applications.resnet50 import ResNet50 as PTModel, preprocess_input\n",
    "elif BASE_MODEL=='InceptionV3':\n",
    "    from keras.applications.inception_v3 import InceptionV3 as PTModel, preprocess_input\n",
    "elif BASE_MODEL=='Xception':\n",
    "    from keras.applications.xception import Xception as PTModel, preprocess_input\n",
    "elif BASE_MODEL=='DenseNet169': \n",
    "    from keras.applications.densenet import DenseNet169 as PTModel, preprocess_input\n",
    "elif BASE_MODEL=='DenseNet121':\n",
    "    from keras.applications.densenet import DenseNet121 as PTModel, preprocess_input\n",
    "else:\n",
    "    raise ValueError('Unknown model: {}'.format(BASE_MODEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "a068b664c8bb465938fa3974c7b6e6120bf0860e"
   },
   "outputs": [],
   "source": [
    "img_gen_args = dict(samplewise_center=False, \n",
    "                              samplewise_std_normalization=False, \n",
    "                              horizontal_flip = True, \n",
    "                              vertical_flip = False, \n",
    "                              height_shift_range = 0.05, \n",
    "                              width_shift_range = 0.02, \n",
    "                              rotation_range = 3, \n",
    "                              shear_range = 0.01,\n",
    "                              fill_mode = 'nearest',\n",
    "                              zoom_range = 0.05,\n",
    "                               preprocessing_function=preprocess_input)\n",
    "img_gen = ImageDataGenerator(**img_gen_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "9a3983f1be91084ba8c04441280efb18290814f2"
   },
   "outputs": [],
   "source": [
    "def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, seed = None, **dflow_args):\n",
    "    base_dir = os.path.dirname(in_df[path_col].values[0])\n",
    "    print('## Ignore next message from keras, values are replaced anyways: seed: {}'.format(seed))\n",
    "    df_gen = img_data_gen.flow_from_directory(base_dir, \n",
    "                                     class_mode = 'sparse',\n",
    "                                              seed = seed,\n",
    "                                    **dflow_args)\n",
    "    df_gen.filenames = in_df[path_col].values\n",
    "    df_gen.classes = np.stack(in_df[y_col].values,0)\n",
    "    df_gen.samples = in_df.shape[0]\n",
    "    df_gen.n = in_df.shape[0]\n",
    "    #print(\"HERE:\")\n",
    "    #print(df_gen.n)\n",
    "    #df_gen._set_index_array()\n",
    "    df_gen.index_array = np.arange(df_gen.n)\n",
    "    if df_gen.shuffle:\n",
    "        df_gen.index_array = np.random.permutation(df_gen.n)\n",
    "    df_gen.directory = '' # since we have the full path\n",
    "    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n",
    "    print(\"df_gen.n = \")\n",
    "    print(df_gen.n)\n",
    "    return df_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "720a67aaa3a8f4c9d5d50752c3f18f4e54dc3af0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Ignore next message from keras, values are replaced anyways: seed: None\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 20547 images\n",
      "df_gen.n = \n",
      "20547\n",
      "## Ignore next message from keras, values are replaced anyways: seed: None\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 5137 images\n",
      "df_gen.n = \n",
      "5137\n",
      "## Ignore next message from keras, values are replaced anyways: seed: None\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 5137 images\n",
      "df_gen.n = \n",
      "5137\n",
      "before next\n",
      "5137\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-c031a6df8202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# used a fixed dataset for evaluating the algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mvalid_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_gen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# one big batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/share/pkg/python/3.6.2/install/lib/python3.6/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg/python/3.6.2/install/lib/python3.6/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m         \"\"\"\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m             \u001b[0mindex_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg/python/3.6.2/install/lib/python3.6/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m_flow_index\u001b[0;34m(self, n, batch_size, shuffle, seed)\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mindex_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             \u001b[0mcurrent_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_index\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mcurrent_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mcurrent_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "train_gen = flow_from_dataframe(img_gen, train_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'class_vec', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = BATCH_SIZE)\n",
    "\n",
    "valid_gen = flow_from_dataframe(img_gen, valid_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'class_vec', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = 256) # we can use much larger batches for evaluation\n",
    "intermediate_gen = flow_from_dataframe(img_gen, \n",
    "                        valid_df, \n",
    "                        path_col = 'path',\n",
    "                        y_col = 'class_vec', \n",
    "                        target_size = IMG_SIZE,\n",
    "                        color_mode = 'rgb',\n",
    "                        batch_size = TEST_SAMPLES)\n",
    "print(\"before next\")\n",
    "print(intermediate_gen.n)\n",
    "# used a fixed dataset for evaluating the algorithm\n",
    "valid_X, valid_Y = next(intermediate_gen) # one big batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "085cf677a4704dce34c679958674a84469e2ef4f"
   },
   "source": [
    "# Show a batch\n",
    "Here we see what the augmentation actually looks like on a few sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "37c9b66822c5dd59162813909c31d384db881026"
   },
   "outputs": [],
   "source": [
    "t_x, t_y = next(train_gen)\n",
    "print(t_x.shape, t_y.shape)\n",
    "fig, m_axs = plt.subplots(2, 4, figsize = (16, 8))\n",
    "for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n",
    "    c_ax.imshow(c_x[:,:,0], cmap = 'bone')\n",
    "    c_ax.set_title('%s' % class_enc.classes_[np.argmax(c_y)])\n",
    "    c_ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f273320778cca1188e3bf7800248ebf06533c61c"
   },
   "source": [
    "# Build our pretrained model\n",
    "Here we build the pretrained model and download the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7ec309826c33787294dd1ba2cac5e4e65bab1755"
   },
   "outputs": [],
   "source": [
    "base_pretrained_model = PTModel(input_shape =  t_x.shape[1:], \n",
    "                              include_top = False, weights = 'imagenet')\n",
    "base_pretrained_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c0af654a22993505bd8dc48355c4bd347b89947a"
   },
   "source": [
    "## Model Supplements\n",
    "Here we add a few other layers to the model to make it better suited for the classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b0f2055383236d17f0d5455ecc2af5de922fc3b8"
   },
   "outputs": [],
   "source": [
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, Conv2D, multiply, LocallyConnected2D, Lambda, AvgPool2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import layers\n",
    "pt_features = Input(base_pretrained_model.get_output_shape_at(0)[1:], name = 'feature_input')\n",
    "pt_depth = base_pretrained_model.get_output_shape_at(0)[-1]\n",
    "from keras.layers import BatchNormalization\n",
    "bn_features = BatchNormalization()(pt_features)\n",
    "gap = GlobalAveragePooling2D()(bn_features)\n",
    "\n",
    "gap_dr = Dropout(DROPOUT)(gap)\n",
    "dr_steps = Dropout(DROPOUT)(Dense(DENSE_COUNT, activation = 'linear', use_bias=False)(gap_dr))\n",
    "dr_steps = BatchNormalization()(dr_steps)\n",
    "dr_steps = layers.LeakyReLU(0.1)(dr_steps)\n",
    "out_layer = Dense(t_y.shape[1], activation = 'softmax')(dr_steps)\n",
    "\n",
    "attn_model = Model(inputs = [pt_features], \n",
    "                   outputs = [out_layer], name = 'trained_model')\n",
    "\n",
    "attn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "74103ef71c30a9725949fbeed864174cbe62c69d"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "pneu_model = Sequential(name = 'combined_model')\n",
    "base_pretrained_model.trainable = False\n",
    "pneu_model.add(base_pretrained_model)\n",
    "pneu_model.add(attn_model)\n",
    "pneu_model.compile(optimizer = Adam(lr = LEARN_RATE), loss = 'categorical_crossentropy',\n",
    "                           metrics = ['categorical_accuracy'])\n",
    "pneu_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0f6ff110ed2db877c1daee57de63e7dc16593c0e"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "weight_path=\"{}_weights.best.hdf5\".format('lung_opacity')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, \n",
    "                                   patience=10, verbose=1, mode='auto', \n",
    "                                   epsilon=0.0001, cooldown=5, min_lr=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=10) # probably needs to be more patient, but kaggle time is limited\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58347af9669fed1e5308ac90a6ce06b3579761c5"
   },
   "outputs": [],
   "source": [
    "train_gen.batch_size = BATCH_SIZE\n",
    "pneu_model.fit_generator(train_gen, \n",
    "                         steps_per_epoch=train_gen.n//BATCH_SIZE,\n",
    "                         validation_data=(valid_X, valid_Y), \n",
    "                         epochs=20, \n",
    "                         callbacks=callbacks_list,\n",
    "                         workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "08e50876364886ef4a39723055136d741597348a"
   },
   "outputs": [],
   "source": [
    "pneu_model.load_weights(weight_path)\n",
    "pneu_model.save('full_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f67dd5726e24517401ff0724f2aa07b1787cf791"
   },
   "outputs": [],
   "source": [
    "pred_Y = pneu_model.predict(valid_X, \n",
    "                          batch_size = BATCH_SIZE, \n",
    "                          verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "40f86cabdbea5e8dfc736882c4e7f5036297ec0a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "plt.matshow(confusion_matrix(np.argmax(valid_Y, -1), np.argmax(pred_Y,-1)))\n",
    "print(classification_report(np.argmax(valid_Y, -1), \n",
    "                            np.argmax(pred_Y,-1), target_names = class_enc.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1c217311f0f08d5473f493244cc4c4e17c0b6e9d"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "fpr, tpr, _ = roc_curve(np.argmax(valid_Y,-1)==0, pred_Y[:,0])\n",
    "fig, ax1 = plt.subplots(1,1, figsize = (5, 5), dpi = 250)\n",
    "ax1.plot(fpr, tpr, 'b.-', label = 'VGG-Model (AUC:%2.2f)' % roc_auc_score(np.argmax(valid_Y,-1)==0, pred_Y[:,0]))\n",
    "ax1.plot(fpr, fpr, 'k-', label = 'Random Guessing')\n",
    "ax1.legend(loc = 4)\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate');\n",
    "ax1.set_title('Lung Opacity ROC Curve')\n",
    "fig.savefig('roc_valid.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "cf0f87166720c24ced3b2eae4b2afe77e6529225"
   },
   "source": [
    "# Make a submission\n",
    "We load in the test images and make a submission using those images and a guess for $x, y$ and the width and height for all values where the model is more than 50% convinced there is something suspicious going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2c8c27edd01ad87653e2c55284d64fa029afc472"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "sub_img_df = pd.DataFrame({'path': \n",
    "              glob('../input/rsna-pneumonia-detection-challenge/stage_2_test_images/*.dcm')})\n",
    "sub_img_df['patientId'] = sub_img_df['path'].map(lambda x: os.path.splitext(os.path.basename(x))[0])\n",
    "sub_img_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "96510ebcc831ef0e9839b4050ba8294c5732fbb3"
   },
   "outputs": [],
   "source": [
    "submission_gen = flow_from_dataframe(img_gen, \n",
    "                                     sub_img_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'patientId', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = BATCH_SIZE,\n",
    "                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9ac79cbc09dce5a09fd05e021792b5ff26eb658e"
   },
   "source": [
    "## Predict for each image twice and average the results\n",
    "We shouldn't get the same answer since the data are being augmented (here at so-called test-time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bd564f016278a31bee570f7d6aedc953ca2ff432"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "sub_steps = 2*sub_img_df.shape[0]//BATCH_SIZE\n",
    "out_ids, out_vec = [], []\n",
    "for _, (t_x, t_y) in zip(tqdm(range(sub_steps)), submission_gen):\n",
    "    out_vec += [pneu_model.predict(t_x)]\n",
    "    out_ids += [t_y]\n",
    "out_vec = np.concatenate(out_vec, 0)\n",
    "out_ids = np.concatenate(out_ids, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "527e6c29c66f2de2ec03b53f8de2406b6d051608"
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(out_vec, columns=class_enc.classes_)\n",
    "pred_df['patientId'] = out_ids\n",
    "pred_avg_df = pred_df.groupby('patientId').agg('mean').reset_index()\n",
    "pred_avg_df['Lung Opacity'].hist()\n",
    "pred_avg_df.to_csv('image_level_class_probs.csv', index=False) # not hte submission file\n",
    "pred_avg_df.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5c7e5670184b1b9e7de9ad842de6ca671731b057"
   },
   "source": [
    "### Simple Strategy\n",
    "We use the `Lung Opacity` as our confidence and predict the image image. It will hopefully do a little bit better than a trivial baseline, and can be massively improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "68ee79e068892d310cc39209517ec20172db8889"
   },
   "outputs": [],
   "source": [
    "pred_avg_df['PredictionString'] = pred_avg_df['Lung Opacity'].map(lambda x: ('%2.2f 0 0 1024 1024' % x) if x>0.5 else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d746f6e21788945f5dc19843811a4e9068302255"
   },
   "outputs": [],
   "source": [
    "pred_avg_df[['patientId', 'PredictionString']].to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
